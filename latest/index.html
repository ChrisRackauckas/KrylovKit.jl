<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · KrylovKit.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>KrylovKit.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href="index.html">Home</a><ul class="internal"><li><a class="toctext" href="#Overview-1">Overview</a></li><li><a class="toctext" href="#Package-features-and-alternatives-1">Package features and alternatives</a></li><li><a class="toctext" href="#Current-functionality-1">Current functionality</a></li><li><a class="toctext" href="#Future-functionality?-1">Future functionality?</a></li></ul></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="man/intro.html">Introduction</a></li><li><a class="toctext" href="man/linear.html">Solving linear systems</a></li><li><a class="toctext" href="man/eig.html">Finding eigenvalues and eigenvectors</a></li><li><a class="toctext" href="man/svd.html">Finding singular values and singular vectors</a></li><li><a class="toctext" href="man/matfun.html">Functions of matrices and linear maps</a></li><li><a class="toctext" href="man/algorithms.html">Available algorithms</a></li><li><a class="toctext" href="man/implementation.html">Details of the implementation</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href="index.html">Home</a></li></ul><a class="edit-page" href="https://github.com/Jutho/KrylovKit.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Home</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="KrylovKit.jl-1" href="#KrylovKit.jl-1">KrylovKit.jl</a></h1><p>A Julia package collecting a number of Krylov-based algorithms for linear problems, singular value and eigenvalue problems and the application of functions of linear maps or operators to vectors.</p><h2><a class="nav-anchor" id="Overview-1" href="#Overview-1">Overview</a></h2><p>KrylovKit.jl accepts general functions or callable objects as linear maps, and general Julia objects with vector like behavior (see below) as vectors.</p><p>The high level interface of KrylovKit is provided by the following functions:</p><ul><li><a href="man/linear.html#KrylovKit.linsolve"><code>linsolve</code></a>: solve linear systems</li><li><a href="man/eig.html#KrylovKit.eigsolve"><code>eigsolve</code></a>: find a few eigenvalues and corresponding eigenvectors</li><li><a href="man/svd.html#KrylovKit.svdsolve"><code>svdsolve</code></a>: find a few singular values and corresponding left and right singular vectors</li><li><a href="man/matfun.html#KrylovKit.exponentiate"><code>exponentiate</code></a>: apply the exponential of a linear map to a vector</li></ul><h2><a class="nav-anchor" id="Package-features-and-alternatives-1" href="#Package-features-and-alternatives-1">Package features and alternatives</a></h2><p>This section could also be titled &quot;Why did I create KrylovKit.jl&quot;?</p><p>There are already a fair number of packages with Krylov-based or other iterative methods, such as</p><ul><li><a href="https://github.com/JuliaMath/IterativeSolvers.jl">IterativeSolvers.jl</a>: part of the   <a href="https://github.com/JuliaMath">JuliaMath</a> organisation, solves linear systems and least   square problems, eigenvalue and singular value problems</li><li><a href="https://github.com/JuliaSmoothOptimizers/Krylov.jl">Krylov.jl</a>: part of the   <a href="https://github.com/JuliaSmoothOptimizers">JuliaSmoothOptimizers</a> organisation, solves   linear systems and least square problems, specific for linear operators from   <a href="https://github.com/JuliaSmoothOptimizers/LinearOperators.jl">LinearOperators.jl</a>.</li><li><a href="https://github.com/lruthotto/KrylovMethods.jl">KrylovMethods.jl</a>: specific for sparse matrices</li><li><a href="https://github.com/acroy/Expokit.jl">Expokit.jl</a>: application of the matrix exponential to a vector</li><li><a href="https://github.com/haampie/ArnoldiMethod.jl">ArnoldiMethod.jl</a>: Implicitly restarted Arnoldi method for eigenvalues of a general matrix</li><li><a href="https://github.com/haampie/JacobiDavidson.jl">JacobiDavidson.jl</a>: Jacobi-Davidson method for eigenvalues of a general matrix</li></ul><p>These packages have certainly inspired and influenced the development of KrylovKit.jl. However, KrylovKit.jl distinguishes itself from the previous packages in the following ways:</p><ol><li><p>KrylovKit accepts general functions to represent the linear map or operator that defines  the problem, without having to wrap them in a <a href="https://github.com/Jutho/LinearMaps.jl"><code>LinearMap</code></a>  or <a href="https://github.com/JuliaSmoothOptimizers/LinearOperators.jl"><code>LinearOperator</code></a> type.  Of course, subtypes of <code>AbstractMatrix</code> are also supported. If the linear map (always the first  argument) is a subtype of <code>AbstractMatrix</code>, matrix vector multiplication is used, otherwise  is applied as a function call.</p></li><li><p>KrylovKit does not assume that the vectors involved in the problem are actual subtypes of  <code>AbstractVector</code>. Any Julia object that behaves as a vector is supported, so in particular  higher-dimensional arrays or any custom user type that supports the following functions  (with <code>v</code> and <code>w</code> two instances of this type and <code>α</code> a scalar (<code>Number</code>)):</p><ul><li><code>Base.eltype(v)</code>: the scalar type (i.e. <code>&lt;:Number</code>) of the data in <code>v</code></li><li><code>Base.similar(v, [T::Type&lt;:Number])</code>: a way to construct additional similar vectors,   possibly with a different scalar type <code>T</code>.</li><li><code>Base.copyto!(w, v)</code>: copy the contents of <code>v</code> to a preallocated vector <code>w</code></li><li><code>Base.fill!(w, α)</code>: fill all the scalar entries of <code>w</code> with value <code>α</code>; this is only   used in combination with <code>α = 0</code> to create a zero vector. Note that <code>Base.zero(v)</code> does   not work for this purpose if we want to change the scalar <code>eltype</code>. We can also not   use <code>rmul!(v, 0)</code> (see below), since <code>NaN*0</code> yields <code>NaN</code>.</li><li><code>LinearAlgebra.mul!(w, v, α)</code>: out of place scalar multiplication; multiply   vector <code>v</code> with scalar <code>α</code> and store the result in <code>w</code></li><li><code>LinearAlgebra.rmul!(v, α)</code>: in-place scalar multiplication of <code>v</code> with <code>α</code>.</li><li><code>LinearAlgebra.axpy!(α, v, w)</code>: store in <code>w</code> the result of <code>α*v + w</code></li><li><code>LinearAlgebra.axpby!(α, v, β, w)</code>: store in <code>w</code> the result of <code>α*v + β*w</code></li><li><code>LinearAlgebra.dot(v,w)</code>: compute the inner product of two vectors</li><li><code>LinearAlgebra.norm(v)</code>: compute the 2-norm of a vector</li></ul><p>Furthermore, KrylovKit provides two types satisfying the above requirements that might  facilitate certain applications:</p><ul><li><a href="@ref"><code>RecursiveVec</code></a> can be used for grouping a set of vectors into a single vector like</li></ul><p>structure (can be used recursively). The reason that e.g. <code>Vector{&lt;:Vector}</code> cannot be used  for this is that it returns the wrong <code>eltype</code> and methods like <code>similar(v, T)</code> and <code>fill!(v, α)</code>  don&#39;t work correctly.</p><ul><li><a href="@ref"><code>InnerProductVec</code></a> can be used to redefine the inner product (i.e. <code>dot</code>) and corresponding</li></ul><p>norm (<code>norm</code>) of an already existing vector like object. The latter should help with implementing  certain type of preconditioners and solving generalized eigenvalue problems with a positive  definite matrix in the right hand side.</p></li></ol><h2><a class="nav-anchor" id="Current-functionality-1" href="#Current-functionality-1">Current functionality</a></h2><p>The following algorithms are currently implemented</p><ul><li><code>linsolve</code>: <a href="man/algorithms.html#KrylovKit.CG"><code>CG</code></a>, <a href="man/algorithms.html#KrylovKit.GMRES"><code>GMRES</code></a></li><li><code>eigsolve</code>: a Krylov-Schur algorithm (i.e. with tick restarts) for extremal eigenvalues of   normal (i.e. not generalized) eigenvalue problems, corresponding to <a href="man/algorithms.html#KrylovKit.Lanczos"><code>Lanczos</code></a> for   real symmetric or complex hermitian linear maps, and to <a href="man/algorithms.html#KrylovKit.Arnoldi"><code>Arnoldi</code></a> for general linear maps.</li><li><code>svdsolve</code>: finding largest singular values based on Golub-Kahan-Lanczos bidiagonalization   (see <a href="man/algorithms.html#KrylovKit.GKL"><code>GKL</code></a>)</li><li><code>exponentiate</code>: a <a href="man/algorithms.html#KrylovKit.Lanczos"><code>Lanczos</code></a> based algorithm for the action of the exponential of   a real symmetric or complex hermitian linear map.</li></ul><h2><a class="nav-anchor" id="Future-functionality?-1" href="#Future-functionality?-1">Future functionality?</a></h2><p>Here follows a wish list / to-do list for the future. Any help is welcomed and appreciated.</p><ul><li>More algorithms, including biorthogonal methods:<ul><li>for <code>linsolve</code>: MINRES, BiCG, BiCGStab(l), IDR(s), ...</li><li>for <code>eigsolve</code>: BiLanczos, Jacobi-Davidson (?) JDQR/JDQZ, subspace iteration (?), ...</li><li>for <code>exponentiate</code>: Arnoldi (currently only Lanczos supported)</li></ul></li><li>Generalized eigenvalue problems: Rayleigh quotient / trace minimization, LO(B)PCG, EIGFP</li><li>Least square problems</li><li>Nonlinear eigenvalue problems</li><li>Preconditioners</li><li>Refined Ritz vectors, Harmonic ritz values and vectors</li><li>Support both in-place / mutating and out-of-place functions as linear maps</li><li>Reuse memory for storing vectors when restarting algorithms</li><li>Improved efficiency for the specific case where <code>x</code> is <code>Vector</code> (i.e. BLAS level 2 operations)</li><li>Block versions of the algorithms</li><li>More relevant matrix functions</li></ul><footer><hr/><a class="next" href="man/intro.html"><span class="direction">Next</span><span class="title">Introduction</span></a></footer></article></body></html>
